# SPDX-License-Identifier: MIT
# Copyright (c) 2025 Mraxzist

import csv, json, sys
from pathlib import Path
from typing import Dict, List

from ....config import API_KEY_MB_DEFAULT, CSV_FIELDS
from ....session import source_subdir
from ....util import collect_items_from_inputs, is_hex_hash
from ...types import BaseSource
from .api import build_session
from .core import get_info_by_hashes, get_by_signature, get_recent

class MalwareBazaarSource(BaseSource):
    def __init__(self) -> None:
        self._name = "malwarebazaar"

    @property
    def name(self) -> str:
        return self._name

    def supported_modes(self):
        return ["hash", "signature", "name"]

    # ---------- helpers ----------
    def _write_csv(self, rows: List[Dict], path: Path):
        path.parent.mkdir(parents=True, exist_ok=True)
        with open(path, "w", newline="", encoding="utf-8") as f:
            w = csv.DictWriter(f, fieldnames=CSV_FIELDS, extrasaction="ignore")
            w.writeheader()
            for r in rows:
                w.writerow({k: ("" if r.get(k) is None else r.get(k)) for k in CSV_FIELDS})

    def _write_json(self, rows: List[Dict], path: Path):
        path.parent.mkdir(parents=True, exist_ok=True)
        with open(path, "w", encoding="utf-8") as f:
            json.dump(rows, f, ensure_ascii=False, indent=2)

    # ---------- entry ----------
    def run(self, *, args, session_dir: Path):
        out_dir = source_subdir(session_dir, self.name)

        api_key = (
            getattr(args, "api_key_malwarebazaar", None)
            or getattr(args, "mb_api_key", None)
            or getattr(args, "api_key", None)
            or API_KEY_MB_DEFAULT
        )
        if not api_key or api_key == "PUT-YOUR-MALWAREBAZAAR-KEY-HERE":
            print("[MB] Missing API key (--api-key-malwarebazaar). Skipping MB.", file=sys.stderr)
            return {"processed": 0}

        session = build_session(
            retries=getattr(args, "retries", 3),
            backoff=getattr(args, "backoff", 1.0),
            proxy=getattr(args, "proxy", None),
        )
        connect_timeout = getattr(args, "connect_timeout", 10.0)
        read_timeout = getattr(args, "read_timeout", 45.0)
        verify_tls = getattr(args, "verify", True)

        mode = getattr(args, "mode", "hash")
        results: List[Dict] = []

        if mode == "hash":
            hashes: List[str] = collect_items_from_inputs(getattr(args, "input", []), "hash")
            # optional single --hash
            if getattr(args, "hash_opt", None) and is_hex_hash(args.hash_opt):
                h = args.hash_opt.strip().lower()
                if h not in hashes:
                    hashes.append(h)
            if not hashes:
                print("[MB] No hashes for --mode hash. Provide -i (file or inline) and/or --hash.", file=sys.stderr)
            else:
                print(f"[MB] Processing {len(hashes)} hash(es)…", file=sys.stderr)
                results.extend(
                    get_info_by_hashes(
                        session, hashes, api_key,
                        connect_timeout=connect_timeout, read_timeout=read_timeout, verify_tls=verify_tls
                    )
                )

        elif mode == "signature":
            sigs: List[str] = collect_items_from_inputs(getattr(args, "input", []), "signature")
            if not sigs:
                print("[MB] No signatures provided. Use -i (file or inline).", file=sys.stderr)
            else:
                limit = int(getattr(args, "limit", 200))
                print(f"[MB] Processing {len(sigs)} signature(s) with limit={limit}…", file=sys.stderr)
                for sig in sigs:
                    results.extend(
                        get_by_signature(
                            session, sig, api_key, limit,
                            connect_timeout=connect_timeout, read_timeout=read_timeout, verify_tls=verify_tls
                        )
                    )

        elif mode == "name":
            names: List[str] = collect_items_from_inputs(getattr(args, "input", []), "name")
            if not names:
                print("[MB] No filenames provided. Use -i (file or inline).", file=sys.stderr)
            else:
                selector = getattr(args, "recent_selector", "100")
                print(f"[MB] Fetching recent '{selector}' and filtering by {len(names)} name(s)…", file=sys.stderr)
                recent = get_recent(
                    session, api_key, selector,
                    connect_timeout=connect_timeout, read_timeout=read_timeout, verify_tls=verify_tls
                )
                qnames = [n.lower() for n in names]
                for r in recent:
                    fn = (r.get("file_name", "") or "").lower()
                    if any(q in fn for q in qnames):
                        results.append(r)


        uniq, seen = [], set()
        for r in results:
            key = (r.get("sha256_hash", ""), r.get("file_name", ""))
            if key in seen:
                continue
            seen.add(key)
            uniq.append(r)

        csv_path = out_dir / "mb_results.csv"
        json_path = out_dir / "mb_results.json"
        self._write_csv(uniq, csv_path)
        self._write_json(uniq, json_path)

        print(f"[MB] Done. Files: {csv_path}, {json_path}", file=sys.stderr)
        return {"processed": len(uniq), "csv": str(csv_path), "json": str(json_path)}
